[{"path":"https://nceas.github.io/metajam/articles/dataset-batch-processing.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Use Case 2 - Processing stream chemistry data for the LTER Luquillo site","text":"vignette aims showcase use case using 2 main functions metajam - download_d1_data read_d1_files using data processing workflow developed NCO synthesis working group Stream Elemental Cycling. datasets used LTER site - Luquillo can found PASTA data repository http://dx.doi.org/doi:10.6073/pasta/f9df56348f510da0113b1e6012fa2967. data package collection 8 datasets stream water samples 8 different locations Luquillo Mountains. goal read data 8 different sampling sites aggregate one harmonized dataset. use metadata check data structures units across 8 different sampling sites performing aggregation.","code":""},{"path":"https://nceas.github.io/metajam/articles/dataset-batch-processing.html","id":"libraries","dir":"Articles","previous_headings":"","what":"Libraries","title":"Use Case 2 - Processing stream chemistry data for the LTER Luquillo site","text":"","code":"#devtools::install_github(\"NCEAS/metajam\") library(metajam)   library(udunits2)  # For wrangling the data library(readr) library(tidyr) library(dplyr) library(purrr) library(stringr)"},{"path":"https://nceas.github.io/metajam/articles/dataset-batch-processing.html","id":"constants","dir":"Articles","previous_headings":"","what":"Constants","title":"Use Case 2 - Processing stream chemistry data for the LTER Luquillo site","text":"","code":"# Download the data from DataONE on your local machine data_folder <- \"Data_SEC\"  # Ammonium to Ammoniacal-nitrogen conversion. We will use this conversion later. coeff_conv_NH4_to_NH4N <- 0.7764676534"},{"path":"https://nceas.github.io/metajam/articles/dataset-batch-processing.html","id":"download-the-datasets","dir":"Articles","previous_headings":"","what":"Download the datasets","title":"Use Case 2 - Processing stream chemistry data for the LTER Luquillo site","text":"point, data metadata downloaded inside main directory; Data_SEC example. metajam organize files follow: dataset stored sub-directory named package DOI file name data: my_data.csv raw EML naming convention file name + __full_metadata.xml: my_data__full_metadata.xml package level metadata summary naming convention file name + __summary_metadata.csv: my_data__summary_metadata.csv relevant, attribute level metadata naming convention file name + __attribute_metadata.csv: my_data__attribute_metadata.csv relevant, factor level metadata naming convention file name + __attribute_factor_metadata.csv: my_data__attribute_factor_metadata.csv","code":"# Create the local directory to store datasets dir.create(data_folder, showWarnings = FALSE)  # Get the datasets unique identifiers test_datasets_listing <- read_csv(system.file(\"extdata\", \"LTER-SEC_DatasetsListing_SearchedData.csv\", package = \"metajam\"))  # Keep only the LUQ related datasets luq_test_datasets <- test_datasets_listing %>%   filter(grepl(\"LUQ\", .$`LTER site abbreviation`)) %>%   select(`LTER site abbreviation`,          `Data Repository (PASTA) URL to Archive/Metadata`,          `Data Repository (PASTA) URL to File`,          `Data Repository (PASTA) Filename`) %>%   na.omit() %>%   arrange(`Data Repository (PASTA) Filename`) # sort the data sets alphabetically  ## Batch download the datasets  # the tidiest way local_datasets <- map(luq_test_datasets$`Data Repository (PASTA) URL to File`, ~download_d1_data(.x, data_folder))  # the apply way # local_datasets <- lapply(luq_test_datasets$`Data Repository (PASTA) URL to File`, download_d1_data, data_folder)  # the map way # local_datasets <- map(luq_test_datasets$`Data Repository (PASTA) URL to File`, function(x) {download_d1_data(x, data_folder)})"},{"path":"https://nceas.github.io/metajam/articles/dataset-batch-processing.html","id":"read-the-data-and-metadata-in-your-r-environment","dir":"Articles","previous_headings":"","what":"Read the data and metadata in your R environment","title":"Use Case 2 - Processing stream chemistry data for the LTER Luquillo site","text":"","code":"# You could list the datasets dowloaded in the `Data_SEC` folder  # local_datasets <- dir(data_folder, full.names = TRUE)  # or you can directly use the outputed paths from download_d1_data  # Read all the datasets and their associated metadata in as a named list luq_datasets <- map(local_datasets, read_d1_files) %>%    set_names(map(., ~.x$summary_metadata$value[.x$summary_metadata$name == \"File_Name\"]))"},{"path":"https://nceas.github.io/metajam/articles/dataset-batch-processing.html","id":"perform-checks-on-data-structure","dir":"Articles","previous_headings":"","what":"Perform checks on data structure","title":"Use Case 2 - Processing stream chemistry data for the LTER Luquillo site","text":"data structure across sampling sites (datasets)? example, datasets column names?","code":"# list all the attributes attributes_luq <- luq_datasets %>% map(\"data\") %>% map(colnames)  # Check if they are identical by comparing all against the first site for(ds in names(attributes_luq)) {   print(identical(attributes_luq[[1]], attributes_luq[[ds]])) }  #> => We are good, same data structure across the sampling sites"},{"path":"https://nceas.github.io/metajam/articles/dataset-batch-processing.html","id":"conclusion","dir":"Articles","previous_headings":"Perform checks on data structure","what":"Conclusion","title":"Use Case 2 - Processing stream chemistry data for the LTER Luquillo site","text":"attributes reported different sampling sites","code":""},{"path":"https://nceas.github.io/metajam/articles/dataset-batch-processing.html","id":"perform-checks-on-the-units","dir":"Articles","previous_headings":"","what":"Perform checks on the units","title":"Use Case 2 - Processing stream chemistry data for the LTER Luquillo site","text":"data reported identical units? example, every dataset CI reported microgramsPerLiter?","code":"# List all the units used luq_units <- luq_datasets %>% map(\"attribute_metadata\") %>% map(~.[[\"unit\"]])  # Check if they are identical by comparing all against the first site for(us in names(luq_units)) {   print(identical(luq_units[[1]], luq_units[[us]])) }  #>!!! => The 2 last datasets have different units!!!!!!!!!!  # Let's check the differences luq_units_merged <- luq_datasets %>%   map(\"attribute_metadata\") %>%   map(. %>% select(attributeName, unit)) %>%   reduce(full_join, by = \"attributeName\")   ## Rename # Create the new names luq_new_colnames <- names(luq_units) %>%   str_split(\"[.]\") %>%   map(~.[1]) %>%   paste(\"unit\", ., sep = \"_\")  # Apply the new names colnames(luq_units_merged) <- c(\"attributeName\", luq_new_colnames)"},{"path":"https://nceas.github.io/metajam/articles/dataset-batch-processing.html","id":"conclusion-1","dir":"Articles","previous_headings":"Perform checks on the units","what":"Conclusion","title":"Use Case 2 - Processing stream chemistry data for the LTER Luquillo site","text":"2 last sampling sites RioIcacos RioMameyesPuenteRoto, units used gage height (“Gage_Ht”) feet meters like sites 2 last sampling sites RioIcacos RioMameyesPuenteRoto, NH4 NH4-N measured","code":""},{"path":"https://nceas.github.io/metajam/articles/dataset-batch-processing.html","id":"fixing-units-discrepancies","dir":"Articles","previous_headings":"","what":"Fixing units discrepancies","title":"Use Case 2 - Processing stream chemistry data for the LTER Luquillo site","text":"","code":"# fix attribute naming discrepancies -- to be improved  # Copy the units for Gage height luq_units_merged <- luq_units_merged %>%    mutate(unit_RioIcacos = ifelse(attributeName == \"Gage_Ht\", \"foot\", unit_RioIcacos),          unit_RioMameyesPuenteRoto = ifelse(attributeName == \"Gage_Ht\", \"foot\", unit_RioMameyesPuenteRoto))   # Copy the units for NH4 luq_units_merged <- luq_units_merged %>%    mutate(unit_RioIcacos = ifelse(attributeName == \"NH4-N\", \"microgramsPerLiter\", unit_RioIcacos),          unit_RioMameyesPuenteRoto = ifelse(attributeName == \"NH4-N\", \"microgramsPerLiter\", unit_RioMameyesPuenteRoto))   # drop the 2 last rows luq_units_merged <- head(luq_units_merged, -2)   ### Implement the unit conversion for RioIcacos and RioMameyesPuenteRoto ----  # Simplify naming RioIcacos_data <- luq_datasets$RioIcacos$data RioIcacos_attrmeta <- luq_datasets$RioIcacos$attribute_metadata   ## RioIcacos # Fix NAs. In this dataset \"-9999\" is the missing value code. So we need to replace those with NAs RioIcacos_data <- na_if(RioIcacos_data, \"-9999\")  # Do the unit conversion    #Check to see if you can use the udunits package to convert feet to meters  ud.are.convertible(\"foot\", \"meter\")  #TRUE, so we can use udunits to do the conversion  # Do the unit conversion in both the data file and the attributes file  - Gage height - udunits way  RioIcacos_data$Gage_Ht <- ud.convert(RioIcacos_data$Gage_Ht, \"foot\", \"meter\")  RioIcacos_attrmeta$unit <-  str_replace_all(RioIcacos_attrmeta$unit, pattern = \"foot\", replacement = \"meter\")   # If we could NOT use udunits to do the conversion we could do it manually this way   #RioIcacos_data <- RioIcacos_data %>% mutate( `Gage_Ht` = `Gage_Ht`* 0.3048)  # Do the unit conversion for RioIcacos and RioMameyesPuenteRoto - NH4 to NH4-N  #Check to see if you can use udunits to convert the measurements you want to convert.  ud.are.convertible(\"NH4\", \"NH4-N\")  #FALSE = Udunits cannot convert these units for us so we will manually convert using the input below  # Ammonium to Ammoniacal-nitrogen conversion coeff_conv_NH4_to_NH4N <- 0.7764676534   # Unit conversion for RioIcacos and RioMameyesPuenteRoto - NH4 to NH4-N RioIcacos_data <- RioIcacos_data %>% mutate( `NH4-N` = `NH4-N`* coeff_conv_NH4_to_NH4N)   # Update the main object  luq_datasets$RioIcacos$data <- RioIcacos_data   ## RioMameyesPuenteRoto  # Simplify naming RioMameyesPuenteRoto_data <- luq_datasets$RioMameyesPuenteRoto$data RioMameyesPuenteRoto_attrmeta <- luq_datasets$RioMameyesPuenteRoto$attribute_metadata  #Replace all cells with the missing value code (\"-9999\") with \"NA\" RioMameyesPuenteRoto_data <- na_if(RioMameyesPuenteRoto_data, \"-9999\")  #Tidy version of unit conversion   RioMameyesPuenteRoto_data$Gage_Ht <- ud.convert(RioMameyesPuenteRoto_data$Gage_Ht, \"foot\", \"meter\") RioMameyesPuenteRoto_attrmeta$unit <-  str_replace_all (RioMameyesPuenteRoto_attrmeta$unit, pattern = \"foot\", replacement = \"meter\")  # Do the unit conversion for RioMameyesPuenteRoto - NH4 to NH4-N (recall that we cannot use udunits for this so we are doing it manually)  #In this dataset the NH4-N column is actually empty, so this is not necessary. But here is how you would do it if you had to.   RioMameyesPuenteRoto_data <- RioMameyesPuenteRoto_data %>% mutate( `NH4-N` = `NH4-N`* coeff_conv_NH4_to_NH4N)  # Update the main object luq_datasets$RioMameyesPuenteRoto$data <- RioMameyesPuenteRoto_data"},{"path":"https://nceas.github.io/metajam/articles/dataset-batch-processing.html","id":"append-all-the-sampling-sites-into-one-master-dataset","dir":"Articles","previous_headings":"","what":"Append all the sampling sites into one master dataset","title":"Use Case 2 - Processing stream chemistry data for the LTER Luquillo site","text":"","code":"# bind the sampling sites data into one master dataset for LUQ all_sites_luq <- luq_datasets %>%   map(\"data\") %>%    bind_rows(.id = \"prov\")  # Replace -9999 with NAs all_sites_luq <- na_if(all_sites_luq, \"-9999\")  # Write as csv write_csv(all_sites_luq, \"stream_chem_all_LUQ.csv\")"},{"path":"https://nceas.github.io/metajam/articles/dataset-batch-processing.html","id":"general-conclusion","dir":"Articles","previous_headings":"","what":"General Conclusion","title":"Use Case 2 - Processing stream chemistry data for the LTER Luquillo site","text":"Although column names datasets / sampling sites, looking metadata discovered 2 sampling sites measuring stream gage height NH4 concentration using different protocols. used metadata perform necessary unit conversions homogenize 8 datasets merging one master dataset. merge process, added provenance column able track origin row, allowing users master datasets check original datasets metadata necessary.","code":""},{"path":"https://nceas.github.io/metajam/articles/dataset-single.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Use Case 1 - Processing a single dataset","text":"vignette aims showcase use case using 2 main functions metajam - download_d1_data read_d1_files download one dataset Arctic Data Center data repository. example, using permafrost data Polaris Project 2017: Sarah Ludwig, Robert M Holmes, Susan Natali, Paul Mann, John Schade, et al. 2018. Polaris Project 2017: Permafrost carbon nitrogen, Yukon-Kuskokwim Delta, Alaska. Arctic Data Center. doi:10.18739/A2KK3F.","code":""},{"path":"https://nceas.github.io/metajam/articles/dataset-single.html","id":"libraries-and-constants","dir":"Articles","previous_headings":"","what":"Libraries and constants","title":"Use Case 1 - Processing a single dataset","text":"","code":"# devtools::install_github(\"NCEAS/metajam\") library(metajam) # Directory to save the data set path_folder <- \"Data_polaris\"  # URL to download the dataset from DataONE data_url <- \"https://arcticdata.io/metacat/d1/mn/v2/object/urn%3Auuid%3Aec704da8-f174-49db-b993-bae479cdc5d9\""},{"path":"https://nceas.github.io/metajam/articles/dataset-single.html","id":"download-the-dataset","dir":"Articles","previous_headings":"","what":"Download the dataset","title":"Use Case 1 - Processing a single dataset","text":"point, data metadata downloaded inside main directory; Data_polaris example. metajam organize files follow: dataset stored sub-directory named package DOI file name data: my_data.csv raw EML naming convention file name + __full_metadata.xml: my_data__full_metadata.xml package level metadata summary naming convention file name + __summary_metadata.csv: my_data__summary_metadata.csv relevant, attribute level metadata naming convention file name + __attribute_metadata.csv: my_data__attribute_metadata.csv relevant, factor level metadata naming convention file name + __attribute_factor_metadata.csv: my_data__attribute_factor_metadata.csv Local file structure dataset downloaded metajam","code":"# Create the local directory to download the datasets dir.create(path_folder, showWarnings = FALSE)  # Download the dataset and associated metdata  data_folder <- metajam::download_d1_data(data_url, path_folder) # data_folder # \"Data_polaris/doi_10.18739_A2KK3F__Polaris_2017_Permafrost\""},{"path":"https://nceas.github.io/metajam/articles/dataset-single.html","id":"read-the-data-and-metadata-in-your-r-environment","dir":"Articles","previous_headings":"","what":"Read the data and metadata in your R environment","title":"Use Case 1 - Processing a single dataset","text":"","code":"# Read all the datasets and their associated metadata in as a named list polaris17_permafrost <- metajam::read_d1_files(data_folder)"},{"path":"https://nceas.github.io/metajam/articles/dataset-single.html","id":"structure-of-the-named-list-object","dir":"Articles","previous_headings":"","what":"Structure of the named list object","title":"Use Case 1 - Processing a single dataset","text":"now loaded R environment one named list object contains data polaris17_permafrost$data, general (summary) metadata polaris17_permafrost$summary_metadata - title, creators, dates, locations - attribute level metadata information polaris17_permafrost$attribute_metadata, allowing user get information, units definitions attributes. Structure named list object containing tabular metadata data loaded metajam","code":""},{"path":"https://nceas.github.io/metajam/articles/package-download.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Use Case 3 - Downloading entire data packages using DOIs","text":"vignette aims showcase use case user wants download datasets data package using metajam - download_d1_data_pkg. example use csv file storing packages returned searching soil bulk density Arctic Data Center KNB data repositories.","code":""},{"path":"https://nceas.github.io/metajam/articles/package-download.html","id":"libraries-and-constants","dir":"Articles","previous_headings":"","what":"Libraries and constants","title":"Use Case 3 - Downloading entire data packages using DOIs","text":"","code":"# devtools::install_github(\"NCEAS/metajam\") library(metajam)   library(readr) library(purrr) # Directory to save the data set path_folder <- \"./Soil_bulk\"  # URL to read the search results stored as a csv on Google Drive csv_search_results_url <- \"https://drive.google.com/uc?export=download&id=1WTLP2BcXCXmUyv4kmntyhuPfrBNdPIqV\""},{"path":"https://nceas.github.io/metajam/articles/package-download.html","id":"download-all-the-datasets-from-data-packages-using-dois","dir":"Articles","previous_headings":"","what":"Download all the datasets from data packages using DOIs","title":"Use Case 3 - Downloading entire data packages using DOIs","text":"","code":"# Create the local directory to store data sets dir.create(path_folder, showWarnings = FALSE)  # Read the data listing from Google Drive: https://drive.google.com/open?id=1WTLP2BcXCXmUyv4kmntyhuPfrBNdPIqV data_listing <- read_csv(csv_search_results_url)   ### Download the data and metadata ----  # Create the list of unique dois dois <- unique(data_listing$identifier)  # batch download the datasets data_folders <- map(dois, ~download_d1_data_pkg(.x, path_folder))"},{"path":"https://nceas.github.io/metajam/articles/reading-raster.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Use Case 3 - Processing a raster dataset","text":"vignette aims showcase overwrite default function used metajam::read_d1_files (spoiler alert readr::read_csv) read none tabular dara. specific vignette, use example reading geotiff file using raster package. example, using shipping routes frequency data used final human impacts model 17 marine ecosystems 22 stressor drivers DOI: 10.5063/F15M63Z8.. information research, please see Micheli F, Halpern BS, Walbridge S, Ciriaco S, Ferretti F, Fraschetti S, et al. (2013) Cumulative Human Impacts Mediterranean Black Sea Marine Ecosystems: Assessing Current Pressures Opportunities. PLoS ONE 8(12). https://doi.org/10.1371/journal.pone.0079889.","code":""},{"path":"https://nceas.github.io/metajam/articles/reading-raster.html","id":"libraries-and-constants","dir":"Articles","previous_headings":"","what":"Libraries and constants","title":"Use Case 3 - Processing a raster dataset","text":"","code":"# devtools::install_github(\"NCEAS/metajam\") library(metajam) library(raster) library(magrittr) # Directory to save the data set path_folder <- \"Human_impacts\"  # URL to download the dataset from DataONE data_url <- \"https://cn.dataone.org/cn/v2/resolve/urn:uuid:6f101827-2fc3-43da-8c8d-7b1f927c4c73\""},{"path":"https://nceas.github.io/metajam/articles/reading-raster.html","id":"download-the-raster-dataset","dir":"Articles","previous_headings":"","what":"Download the raster dataset","title":"Use Case 3 - Processing a raster dataset","text":"point, data metadata downloaded inside main directory; human_impacts example. metajam organize files follow: dataset stored sub-directory named package DOI file name data: shipping.tif raw EML naming convention file name + __full_metadata.xml: shipping__full_metadata.xml package level metadata summary naming convention file name + __summary_metadata.csv: shipping__summary_metadata.csv","code":"# Create the local directory to download the datasets dir.create(path_folder, showWarnings = FALSE)  # Download the dataset and associated metdata  data_folder <- metajam::download_d1_data(data_url, path_folder) # data_folder # \"Human_impacts/doi_10.5063_F15M63Z8__shipping__tif\""},{"path":"https://nceas.github.io/metajam/articles/reading-raster.html","id":"read-the-raster-file-and-metadata-in-your-r-environment","dir":"Articles","previous_headings":"","what":"Read the raster file and metadata in your R environment","title":"Use Case 3 - Processing a raster dataset","text":"Shipping routes frequency","code":"# Read the raster file and its associated metadata in as a named list # using the raster:raster function shipping_routes <-  read_d1_files(data_folder, \"raster\")  # Plot the raster data plot(shipping_routes$data)"},{"path":"https://nceas.github.io/metajam/articles/reading-raster.html","id":"investigate-the-metadata","dir":"Articles","previous_headings":"","what":"Investigate the metadata","title":"Use Case 3 - Processing a raster dataset","text":"","code":"shipping_routes$summary_metadata"},{"path":"https://nceas.github.io/metajam/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Julien Brun. Maintainer, author. Irene Steves. Author.            https://github.com/isteves Mitchell Maier. Author. Nathan Hwangbo. Contributor. Derek Strong. Contributor. Colin Smith. Contributor. Kristen Peach. Contributor.","code":""},{"path":"https://nceas.github.io/metajam/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Brun J, Steves , Maier M (2022). metajam: Easily Download Data Metadata 'DataONE'. https://github.com/nceas/metajam, https://nceas.github.io/metajam/.","code":"@Manual{,   title = {metajam: Easily Download Data and Metadata from 'DataONE'},   author = {Julien Brun and Irene Steves and Mitchell Maier},   year = {2022},   note = {https://github.com/nceas/metajam, https://nceas.github.io/metajam/}, }"},{"path":"https://nceas.github.io/metajam/index.html","id":"metajam","dir":"","previous_headings":"","what":"Easily Download Data and Metadata from DataONE","title":"Easily Download Data and Metadata from DataONE","text":"Download read data metadata repositories DataONE network.","code":""},{"path":"https://nceas.github.io/metajam/index.html","id":"authors","dir":"","previous_headings":"","what":"Authors","title":"Easily Download Data and Metadata from DataONE","text":"Irene Steves, Mitchell Maier Julien Brun; NCEAS","code":""},{"path":"https://nceas.github.io/metajam/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Easily Download Data and Metadata from DataONE","text":"metajam package can installed CRAN: development version metajam package can also installed GitHub using devtools package:","code":"install.packages(\"metajam\") #install.packages(\"devtools\") devtools::install_github('NCEAS/metajam')"},{"path":"https://nceas.github.io/metajam/index.html","id":"workflow","dir":"","previous_headings":"","what":"Workflow","title":"Easily Download Data and Metadata from DataONE","text":"process using metajam follows: Get URL dataset download Download data metadata (metajam::download_d1_data) Read data metadata R (metajam::read_d1_files) steps described greater detail–included examples–.","code":""},{"path":"https://nceas.github.io/metajam/index.html","id":"how-to-get-the-url-to-your-dataset-of-interest-","dir":"","previous_headings":"","what":"How to get the URL to your dataset of interest ?","title":"Easily Download Data and Metadata from DataONE","text":"DataONE currently supported data repository (KNB, Arctic Data Center, EDI/LTER), can right-click Download button specific dataset choose Copy Link Address copy URL clipboard","code":""},{"path":"https://nceas.github.io/metajam/index.html","id":"download-data","dir":"","previous_headings":"","what":"Download data","title":"Easily Download Data and Metadata from DataONE","text":"download data object, specify data object URL local download path download_d1_data function:  output saved folder name {metadata_id}__{file_name}, contains data file associated metadata. metadata follows conventions: {file_name}__summary_metadata.csv - summary metadata tabular format, includes date downloaded, data file name, file/metadata URLs, etc. {file_name}__full_metadata.xml - metadata xml file, downloaded {file_name}__attribute_metadata.csv - attribute metadata tabular format, included metadata xml {file_name}__attribute_factor_metadata.csv - attribute factor metadata tabular format, included metadata xml","code":"library(metajam)  download_d1_data(\"https://arcticdata.io/metacat/d1/mn/v2/object/urn%3Auuid%3A9e123f84-ce0d-4094-b898-c9e73680eafa\", path = \".\")"},{"path":"https://nceas.github.io/metajam/index.html","id":"read-data","dir":"","previous_headings":"","what":"Read data","title":"Easily Download Data and Metadata from DataONE","text":"read_d1_files function allows read downloaded data metadata directly R environment. Simply run function folder path downloaded objects, data metadata files returned data frames stored list. Use {object_name}$data access data, {object_name}${metadata_type}_metadata access associated metadata.","code":"schools <- read_d1_files(\"./doi_10.18739_A2DP3X__Alaska_Schools_Rentention2009_15\")"},{"path":"https://nceas.github.io/metajam/index.html","id":"additional-resources-for-metajam","dir":"","previous_headings":"","what":"Additional resources for metajam","title":"Easily Download Data and Metadata from DataONE","text":"Recent presentation metajam functionalities: Click metajam demo: Click Package website: https://nceas.github.io/metajam/","code":""},{"path":"https://nceas.github.io/metajam/index.html","id":"acknowledgements","dir":"","previous_headings":"","what":"Acknowledgements","title":"Easily Download Data and Metadata from DataONE","text":"Work package supported : NSF-PLR grant #1546024 M. B. Jones, S. Baker-Yeboah, J. Dozier, M. Schildhauer, . Budden Long Term Ecological Research (LTER) National Communications Office (LNCO), NSF grant #1545288 F. Davis, M. Schildhauer, S. Rebich Hespanha, J. Caselle C. Blanchette Thanks also go NCEAS computing team members Mark Schildhauer, Peter Slaughter, Dominic Muellen, Steven Chong, Jesse Goldstein Matt Jones inputs package. NCEAS logo","code":""},{"path":"https://nceas.github.io/metajam/reference/check_version.html","id":null,"dir":"Reference","previous_headings":"","what":"Check PID version — check_version","title":"Check PID version — check_version","text":"function takes identifier checks see obsoleted.","code":""},{"path":"https://nceas.github.io/metajam/reference/check_version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check PID version — check_version","text":"","code":"check_version(pid, formatType = NULL)"},{"path":"https://nceas.github.io/metajam/reference/check_version.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check PID version — check_version","text":"pid (character) persistent identifier data, metadata, resource map object DataONE member node. formatType (character) Optional. format type return (one data, metadata, resource).","code":""},{"path":"https://nceas.github.io/metajam/reference/check_version.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check PID version — check_version","text":"(data.frame) data frame object version PIDs related information.","code":""},{"path":"https://nceas.github.io/metajam/reference/check_version.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check PID version — check_version","text":"","code":"if (FALSE) { # Most data URLs and identifiers work check_version(\"https://cn.dataone.org/cn/v2/resolve/urn:uuid:a2834e3e-f453-4c2b-8343-99477662b570\") check_version(\"doi:10.18739/A2ZF6M\")  # Specify a formatType (data, metadata, or resource) check_version(\"doi:10.18739/A2ZF6M\", formatType = \"metadata\")  # Returns a warning if the identifier has been obsoleted check_version(\"doi:10.18739/A2HF7Z\", formatType = \"metadata\")  # Returns an error if no matching identifiers are found check_version(\"a_test_pid\")  # Returns a warning if several identifiers are returned check_version(\"10.18739/A2057CR99\") }"},{"path":"https://nceas.github.io/metajam/reference/download_d1_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Download data and metadata from DataONE — download_d1_data","title":"Download data and metadata from DataONE — download_d1_data","text":"Downloads data object DataONE along metadata.","code":""},{"path":"https://nceas.github.io/metajam/reference/download_d1_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download data and metadata from DataONE — download_d1_data","text":"","code":"download_d1_data(data_url, path, dir_name = NULL)"},{"path":"https://nceas.github.io/metajam/reference/download_d1_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download data and metadata from DataONE — download_d1_data","text":"data_url (character) identifier URL DataONE object download. path (character) Path directory download data . dir_name (character) (Optional) Desired name folder containing downloaded data. Defaults data file name.","code":""},{"path":"https://nceas.github.io/metajam/reference/download_d1_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download data and metadata from DataONE — download_d1_data","text":"(character) Path data downloaded .","code":""},{"path":[]},{"path":"https://nceas.github.io/metajam/reference/download_d1_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download data and metadata from DataONE — download_d1_data","text":"","code":"if (FALSE) { soi_moist_path <- download_d1_data(                      data_url = \"urn:uuid:a2834e3e-f453-4c2b-8343-99477662b570\",                      path = tempdir()) download_d1_data(     data_url = \"https://cn.dataone.org/cn/v2/resolve/urn:uuid:a2834e3e-f453-4c2b-8343-99477662b570\",     path = tempdir(),     dir_name = \"test\"     ) }"},{"path":"https://nceas.github.io/metajam/reference/download_d1_data_pkg.html","id":null,"dir":"Reference","previous_headings":"","what":"Download all data and metadata of a data package from DataONE — download_d1_data_pkg","title":"Download all data and metadata of a data package from DataONE — download_d1_data_pkg","text":"Downloads data objects data package DataONE along metadata.","code":""},{"path":"https://nceas.github.io/metajam/reference/download_d1_data_pkg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download all data and metadata of a data package from DataONE — download_d1_data_pkg","text":"","code":"download_d1_data_pkg(meta_obj, path)"},{"path":"https://nceas.github.io/metajam/reference/download_d1_data_pkg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download all data and metadata of a data package from DataONE — download_d1_data_pkg","text":"meta_obj (character) DOI metadata object PID DataONE package download. path (character) Path directory download data .","code":""},{"path":"https://nceas.github.io/metajam/reference/download_d1_data_pkg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download all data and metadata of a data package from DataONE — download_d1_data_pkg","text":"(list) Paths data downloaded .","code":""},{"path":[]},{"path":"https://nceas.github.io/metajam/reference/download_d1_data_pkg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download all data and metadata of a data package from DataONE — download_d1_data_pkg","text":"","code":"if (FALSE) { download_d1_data_pkg(\"doi:10.18739/A2028W\", \".\") download_d1_data_pkg(\"https://doi.org/10.18739/A2028W\", \".\") }"},{"path":"https://nceas.github.io/metajam/reference/metajam.html","id":null,"dir":"Reference","previous_headings":"","what":"metajam package — metajam","title":"metajam package — metajam","text":"Metadata jam - bringing data metadata together","code":""},{"path":"https://nceas.github.io/metajam/reference/metajam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"metajam package — metajam","text":"See GitHub","code":""},{"path":"https://nceas.github.io/metajam/reference/read_d1_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Read data and metadata based on download_d1_data() file structure — read_d1_files","title":"Read data and metadata based on download_d1_data() file structure — read_d1_files","text":"Reads data along metadata R environment based download_d1_data() file structure.","code":""},{"path":"https://nceas.github.io/metajam/reference/read_d1_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read data and metadata based on download_d1_data() file structure — read_d1_files","text":"","code":"read_d1_files(folder_path, fnc = \"read_csv\", ...)"},{"path":"https://nceas.github.io/metajam/reference/read_d1_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read data and metadata based on download_d1_data() file structure — read_d1_files","text":"folder_path (character) Path directory data metadata located. fnc (character) Function used read data (default readr::read_csv()). ... Parameters pass function specified fnc.","code":""},{"path":"https://nceas.github.io/metajam/reference/read_d1_files.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read data and metadata based on download_d1_data() file structure — read_d1_files","text":"(list) Named list containing data metadata data frames.","code":""},{"path":[]},{"path":"https://nceas.github.io/metajam/reference/read_d1_files.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read data and metadata based on download_d1_data() file structure — read_d1_files","text":"","code":"data_folder <- system.file(\"extdata\", \"test_data\", package = \"metajam\") soil_moist_data <- read_d1_files(data_folder) #> Rows: 21 Columns: 11 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr  (1): Date #> dbl (10): Unmanipulated Moisture (cm3 cm-3), Unmanipulated Moisure (SE), Unb... #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. #> Rows: 11 Columns: 9 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr (9): attributeName, attributeDefinition, formatString, measurementScale,... #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. #> Rows: 17 Columns: 2 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr (2): name, value #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.  # You can specify the function you would like to use to read the file and pass parameters soil_moist_data_skipped <- read_d1_files(data_folder, \"read.csv\",                                          skip = 8, stringsAsFactors = FALSE) #> Rows: 11 Columns: 9 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr (9): attributeName, attributeDefinition, formatString, measurementScale,... #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. #> Rows: 17 Columns: 2 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr (2): name, value #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."},{"path":"https://nceas.github.io/metajam/reference/tabularize_eml.html","id":null,"dir":"Reference","previous_headings":"","what":"Get tabular metadata — tabularize_eml","title":"Get tabular metadata — tabularize_eml","text":"function takes path EML (.xml) metadata file returns data frame.","code":""},{"path":"https://nceas.github.io/metajam/reference/tabularize_eml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get tabular metadata — tabularize_eml","text":"","code":"tabularize_eml(eml, full = FALSE)"},{"path":"https://nceas.github.io/metajam/reference/tabularize_eml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get tabular metadata — tabularize_eml","text":"eml emld class object, path EML (.xml) metadata file, raw EML object. full (logical) Returns commonly used metadata fields default. full = TRUE specified, full set metadata fields returned.","code":""},{"path":"https://nceas.github.io/metajam/reference/tabularize_eml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get tabular metadata — tabularize_eml","text":"(data.frame) data frame selected EML values.","code":""},{"path":"https://nceas.github.io/metajam/reference/tabularize_eml.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get tabular metadata — tabularize_eml","text":"","code":"eml <- system.file(\"extdata\", \"test_data\", \"SoilMois2012_2017__full_metadata.xml\",                   package = \"metajam\")    tabularize_eml(eml) #> # A tibble: 16 × 2 #>    name                                       value                              #>    <chr>                                      <chr>                              #>  1 abstract                                   Fire severity is increasing acros… #>  2 eml.version                                eml://ecoinformatics.org/eml-2.1.… #>  3 geographicCoverage.eastBoundingCoordinate  161.4067                           #>  4 geographicCoverage.geographicDescription   Far northeastern Siberia near Che… #>  5 geographicCoverage.northBoundingCoordinate 68.7433                            #>  6 geographicCoverage.southBoundingCoordinate 68.7433                            #>  7 geographicCoverage.westBoundingCoordinate  161.4067                           #>  8 keyword                                    None; fire; permafrost; Siberia; … #>  9 methods                                    <title>Surface soil moisture<\/tit… #> 10 objectName                                 Alexander_Exp Burn Soil Mois 2012… #> 11 people                                     Alexander; Heather; D.; Michael; … #> 12 taxonomicCoverage                          Larix cajanderi                    #> 13 temporalCoverage.beginDate                 2012-07-01                         #> 14 temporalCoverage.endDate                   2017-08-01                         #> 15 title                                      Surface soil moisture across an e… #> 16 url                                        download; https://cn.dataone.org/…"}]
